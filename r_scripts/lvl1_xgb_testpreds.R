


# lvl1_xgb_testpreds

# can we experiment with predicting on the models generated by level one so far (get a feel for public leaderboard)
# 2 things we're interested in here:
#    1)   loading in the cross-referenced train predictions for generating level 2 predictions
#    1.5) will also want to determine local accuracy for stacked predictions from level 1
#    2)   loading in pre-trained models and generating test predictions to test PLB for level 1 so far


source("r_scripts/lvl1_xgb_config.R")
test <- readRDS("input/test.rds")
samp <- read.csv("input/sample_submission.csv", stringsAsFactors = F)
lvl1_results <- read.csv("cache/level1_results.csv", stringsAsFactors = F)



# test a single model's pipeline:
files_mods <- list.files(fp_dir_models)
files_preds <- list.files(fp_dir_preds)
files_feats <- list.files(fp_dir_feats)
num_pred_sets <- nrow(lvl1_results)



# single model holdout gini / PLB gini comparison -----------------------------------------------

lvl1_results %>% filter(eval_metric == "logloss") %>%
    arrange(cv_score) %>% 
    select(-paramkey) %>%
    top_n(10, -cv_score)

# let's use level 1 and iteration 0036 for first gini / plb gini comparison
single_mod <- readRDS(list.files(fp_dir_models, full.names = T)[grepl("0036", list.files(fp_dir_models))])
single_feats <- readRDS(list.files(fp_dir_feats, full.names = T)[grepl("0036", list.files(fp_dir_models))])
single_HO <- trainHO %>% select(single_feats)
single_HO_dmat <- xgb.DMatrix(as.matrix(single_HO))
single_HO_preds <- predict(single_mod, single_HO_dmat)
normalizedGini(YHO, single_HO_preds)


single_test <- test %>% select(single_feats)
single_test_dmat <- xgb.DMatrix(as.matrix(single_test))
single_test_preds <- predict(single_mod, single_test_dmat)
single_test_sub <- data.frame(id=test$id, target=single_test_preds)
write.csv(single_test_sub, "subs/06_0036_0dot268_ho_gini_single_best_logloss.csv", row.names = F)

    #' 0036 logloss model scored 0.268 gini for local holdout and 0.269 on public leader board








# loading and process training preds (for level 2 FINAL stacker - will need another version for intermediate stacker) ---------
library(glmnet)

load("cache/level1_files.RData")
rm(train, trainA, trainB, Y) # I just want idA, idB, idHO, YA, YB, YHO 
gc()


stack1_preds <- paste0("_01_", "preds_", sprintf("%04.0f", 1:max(lvl1_results$iteration)))
stack1_feats <- paste0("_01_", "feats_", sprintf("%04.0f", 1:max(lvl1_results$iteration)))


stack1_preds_mat <- matrix(rep(rep(0, (length(YA) + length(YB))), length(stack1_preds)), ncol=length(stack1_preds))
for(i in 1:length(stack1_preds)) {
    
    stack1_preds_ <- readRDS(list.files("cache/level1_preds", full.names = T)[grepl(stack1_preds[i], list.files("cache/level1_preds"))])
    if(i == 1) {
        ids_ <- stack1_preds_$id  # store ids on first iteration, assert that id's on all files loaded in match
    } else {
        assert_that(all(stack1_preds_$id == ids_))
    }
    stack1_preds_mat[, i] <- stack1_preds_[, 2]
}

glmn_cv1 <- cv.glmnet(x=stack1_preds_mat, y=c(YA, YB), family="binomial")
plot(glmn_cv1)


files_preds








# generating level1 test predictions --------------------------------------------------------------


# initialize a zero'd-out matrix to gather predictions
test_pred_mat <- matrix(rep(rep(0, nrow(test)), num_pred_sets), nrow=nrow(test))
for(i in 1:num_pred_sets) {
    
    
        # # single model isolation
        # best auc so far -- 31
        # i <- 1
    
    
    # read in feats used for this model and subset test by those
    feats_ <- readRDS(file.path(fp_dir_feats, files_feats[i]))
    test_dmat_ <- xgb.DMatrix(as.matrix(test[, feats_]))
    
    # read in model and pass test features into it for predictions
    xgb_mod_ <- readRDS(file.path(fp_dir_models, files_mods[i]))
    test_preds_ <- predict(xgb_mod_, test_dmat_)
    test_pred_mat[, i] <- test_preds_
        
    
        # # single model sub:
        # single_sub <- data.frame(id=test$id, target=test_preds_)
        # write.csv(single_sub, "subs/03_best_error_after_35_iters.csv", row.names = F)
            
}


# bag all (mean) the values across rows (different models) to get mean score
test_pred_mat_bagged <- apply(test_pred_mat, 1, mean)
bagged_sub <- data.frame(id=test$id, target=test_pred_mat_bagged)
write.csv(bagged_sub, "subs/05_bagged_sub_all_after_94_iters.csv", row.names=F)



# correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
test_pred_cor <- cor(test_pred_mat)
corrplot(test_pred_cor, method=c("ellipse"), type="lower")
corrplot(test_pred_cor, method=c("number"), type="lower")

hist(test_pred_mat[, 5], col='light blue')




# submission format
sub <- data.frame(id=samp$id, target=test_pred_mat_bagged)


# can also feed these into a second model 


