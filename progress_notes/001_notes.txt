I combined the output of 118 of my level1 randomized models using a glmnet elasticnet model, this was the result. I jumped roughly 900 spots on the leaderboard and drastically improved upon my score. I believe that an xgboost final model stacker will do even better, as it will be able to pick up on the more subtle nuances in the data. Ultimately I'd like to use both and bag them at the end to give an even better representation of what the true values are.